# Token Management Strategy - Implementation Plan

## üìä –ê–Ω–∞–ª–∏–∑ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞

### –ö–æ–Ω—Å—Ç–∞—Ç–∞—Ü–∏–∏ –æ—Ç —Å–∏–º—É–ª–∞—Ü–∏—è—Ç–∞:
- **Baseline (system + tools):** 5,059 tokens (fixed)
- **Average turn size:** 744 tokens (4 messages)
- **6 messages history:** ~6,175 tokens (3% –æ—Ç 200K –ª–∏–º–∏—Ç–∞)
- **12 messages history:** ~7,291 tokens (3.6% –æ—Ç –ª–∏–º–∏—Ç–∞)
- **20 messages history:** ~8,779 tokens (4.4% –æ—Ç –ª–∏–º–∏—Ç–∞)

### ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–ê –ù–ê–•–û–î–ö–ê:

**–ò—Å—Ç–æ—Ä–∏—è —Å 6-20 —Å—ä–æ–±—â–µ–Ω–∏—è –ù–ï –ú–û–ñ–ï –¥–∞ –¥–æ—Å—Ç–∏–≥–Ω–µ 206K tokens!**

–¢–æ–≤–∞ –æ–∑–Ω–∞—á–∞–≤–∞, —á–µ –ø—Ä–æ–±–ª–µ–º—ä—Ç –µ –≤:

1. **Multiple tool calls –≤ –µ–¥–∏–Ω turn** - Claude –ø—Ä–∞–≤–∏ 5-10 tool calls –Ω–∞–≤–µ–¥–Ω—ä–∂
2. **Large tool results –Ω–µ —Å–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏** - –Ω—è–∫–æ–∏ tools –≤—Ä—ä—â–∞—Ç –æ–≥—Ä–æ–º–Ω–∏ –¥–∞–Ω–Ω–∏
3. **Repeated tool calls** - Claude –ø—Ä–∞–≤–∏ —Å—ä—â–∏—è tool call –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ
4. **Accumulation in single request** - –≤—Å–∏—á–∫–∏ tool results —Å–µ —Ç—Ä—É–ø–∞—Ç –≤ –ï–î–ò–ù request

---

## üîç Root Causes

### 1. Multi-Tool Execution Loop
```javascript
// –í quendooClaudeIntegration.js (line 711-815)
const maxLoops = 10;
while (loopCount < maxLoops) {
  const response = await this.anthropic.messages.create(requestParams);
  // –ê–∫–æ Claude –∏—Å–∫–∞ tools, –¥–æ–±–∞–≤—è tool_results –≤ history
  // –°–ª–µ–¥ —Ç–æ–≤–∞ –ø—Ä–∞–≤–∏ –ù–û–í request —Å –ù–ê–†–ê–°–¢–í–ê–©–ê –∏—Å—Ç–æ—Ä–∏—è
}
```

**–ü—Ä–æ–±–ª–µ–º:** –í—Å–µ–∫–∏ loop –¥–æ–±–∞–≤—è tool results –∫—ä–º –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –ü–†–ï–î–ò —Å–ª–µ–¥–≤–∞—â–∏—è request.

–ü—Ä–∏ 5 tool calls √ó 590 tokens/result = **2,950 tokens** –¥–æ–±–∞–≤–µ–Ω–∏ –∫—ä–º –∏—Å—Ç–æ—Ä–∏—è—Ç–∞!

### 2. Tool Result Size
- Document search: **590 tokens** (3 excerpts √ó 800 chars)
- Make call transcript: **442 tokens**
- List documents: **411 tokens**

**–ü—Ä–æ–±–ª–µ–º:** –ü—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–æ searches (–Ω–∞–ø—Ä. Claude —Ç—ä—Ä—Å–∏ 3-4 –ø—ä—Ç–∏), tool results —Å–µ –Ω–∞—Ç—Ä—É–ø–≤–∞—Ç.

### 3. No Result Cleanup
–°–ª–µ–¥ –∫–∞—Ç–æ tool result —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –æ—Ç Claude, —Ç–æ–π –û–°–¢–ê–í–ê –≤ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –∑–∞–≤–∏–Ω–∞–≥–∏.

**–ü—Ä–æ–±–ª–µ–º:** –°—Ç–∞—Ä–∏—Ç–µ tool results –Ω–µ —Å–µ –∏–∑—á–∏—Å—Ç–≤–∞—Ç, –¥–æ—Ä–∏ –¥–∞ —Å–∞ –∏—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏.

---

## ‚ú® –†–ï–®–ï–ù–ò–Ø

### Solution 1: **Smart Truncation** (RECOMMENDED) ‚≠ê

–ü—Ä–µ–º–∞—Ö–≤–∞–π tool_result —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ –æ—Ç —Å—Ç–∞—Ä–∏ —Å—ä–æ–±—â–µ–Ω–∏—è, –Ω–æ –ü–ê–ó–ò —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ç–∞ –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç.

#### Implementation:

```javascript
// –í quendooClaudeIntegration.js
function smartTruncateHistory(history, keepLastNTurns = 3) {
  const keepLastNMessages = keepLastNTurns * 4; // 4 messages per turn

  if (history.length <= keepLastNMessages) {
    return history; // No truncation needed
  }

  const truncated = [];

  for (let i = 0; i < history.length; i++) {
    const msg = history[i];
    const isRecent = i >= history.length - keepLastNMessages;

    if (isRecent) {
      // Keep recent messages fully
      truncated.push(msg);
    } else {
      // Truncate old tool results
      if (msg.role === 'user' && msg.content.some(c => c.type === 'tool_result')) {
        truncated.push({
          role: 'user',
          content: msg.content.map(c => {
            if (c.type === 'tool_result') {
              return {
                type: 'tool_result',
                tool_use_id: c.tool_use_id,
                content: '[Result truncated to save tokens]'
              };
            }
            return c;
          })
        });
      } else if (msg.role === 'assistant' && msg.content.some(c => c.type === 'tool_use')) {
        // Keep tool_use structure but not parameters
        truncated.push({
          role: 'assistant',
          content: msg.content.map(c => {
            if (c.type === 'tool_use') {
              return {
                type: 'tool_use',
                id: c.id,
                name: c.name,
                input: {} // Remove large input parameters
              };
            }
            return c; // Keep text blocks
          })
        });
      } else {
        // Keep user/assistant text messages
        truncated.push(msg);
      }
    }
  }

  return truncated;
}

// Apply before each request:
history = smartTruncateHistory(history, 3); // Keep last 3 turns fully
```

**–û—á–∞–∫–≤–∞–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏:**
- –°—Ç–∞—Ä–∏—Ç–µ tool results: 590 tokens ‚Üí **10 tokens** (~98% –Ω–∞–º–∞–ª–µ–Ω–∏–µ)
- –ò—Å—Ç–æ—Ä–∏—è –æ—Ç 20 messages ‚Üí **~6,000 tokens** –≤–º–µ—Å—Ç–æ ~18,000 tokens
- Margin –∑–∞ —Å–ª–æ–∂–Ω–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏: **~194K tokens** –Ω–∞–ª–∏—á–Ω–∏

---

### Solution 2: **Reduce Tool Result Size** (QUICK WIN) ‚ö°

–ù–∞–º–∞–ª–∏ —Ä–∞–∑–º–µ—Ä–∞ –Ω–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–Ω–∏ tool results.

#### Implementation:

**A) Document Search - –Ω–∞–º–∞–ª–∏ excerpt size**
```javascript
// –í documentTools.js –∏ document_service.py
excerpt: result.textChunk.substring(0, 500) // –í–º–µ—Å—Ç–æ 800
```

**B) Document Search - –Ω–∞–º–∞–ª–∏ –±—Ä–æ–π results**
```javascript
// –í documentTools.js
const topK = Math.min(Math.max(params.topK || 2, 1), 5); // –í–º–µ—Å—Ç–æ 3 default, 10 max
```

**C) Make Call - limit transcript**
```python
# –í quendoo/tools.py
transcript: call_result.transcript[:500] if call_result.transcript else "" // Limit to 500 chars
```

**–û—á–∞–∫–≤–∞–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏:**
- Document search: 590 ‚Üí **~350 tokens** (40% –Ω–∞–º–∞–ª–µ–Ω–∏–µ)
- Make call: 442 ‚Üí **~250 tokens** (43% –Ω–∞–º–∞–ª–µ–Ω–∏–µ)
- –ü—Ä–∏ 3 turns √ó 350 tokens = **1,050 tokens** history –≤–º–µ—Å—Ç–æ 2,232 tokens

---

### Solution 3: **Rate Limiting Tool Calls** (PREVENTION) üõ°Ô∏è

–û–≥—Ä–∞–Ω–∏—á–∏ –±—Ä–æ—è tool calls –≤ –µ–¥–∏–Ω turn, –∑–∞ –¥–∞ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—à token explosion.

#### Implementation:

```javascript
// –í quendooClaudeIntegration.js (line 732-815)
const MAX_TOOLS_PER_TURN = 3; // Limit to 3 tool calls per turn

if (response.stop_reason === 'tool_use') {
  const toolBlocks = response.content.filter(b => b.type === 'tool_use');

  if (toolBlocks.length > MAX_TOOLS_PER_TURN) {
    console.warn(`[Quendoo] Too many tool calls (${toolBlocks.length}), limiting to ${MAX_TOOLS_PER_TURN}`);

    // Execute only first N tools
    const limitedBlocks = toolBlocks.slice(0, MAX_TOOLS_PER_TURN);

    // Return partial error for remaining tools
    const remainingTools = toolBlocks.slice(MAX_TOOLS_PER_TURN);
    for (const block of remainingTools) {
      toolResults.push({
        type: 'tool_result',
        tool_use_id: block.id,
        content: JSON.stringify({
          error: 'Too many tool calls in one turn. Please try again in next message.'
        }),
        is_error: true
      });
    }
  }
}
```

**–û—á–∞–∫–≤–∞–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏:**
- –ú–∞–∫—Å–∏–º—É–º 3 tool calls √ó 590 tokens = **1,770 tokens** per turn
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç—è–≤–∞ token explosion –æ—Ç 10+ tool calls

---

### Solution 4: **Token Usage Monitoring** (VISIBILITY) üìä

Track actual token usage from Claude API response.

#### Implementation:

```javascript
// –í quendooClaudeIntegration.js (line 720)
const response = await this.anthropic.messages.create(requestParams);

// Log actual token usage from API
if (response.usage) {
  console.log(`[Quendoo] Actual token usage:`,
    `input=${response.usage.input_tokens}`,
    `output=${response.usage.output_tokens}`,
    `total=${response.usage.input_tokens + response.usage.output_tokens}`
  );

  // Alert if approaching limit
  if (response.usage.input_tokens > 180000) {
    console.error(`‚ö†Ô∏è [Quendoo] TOKEN LIMIT WARNING: ${response.usage.input_tokens} / 200000 tokens (${(response.usage.input_tokens / 200000 * 100).toFixed(1)}%)`);
  }
}
```

**–û—á–∞–∫–≤–∞–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏:**
- Real-time visibility –≤ token usage
- Early warning –ø—Ä–∏ –ø—Ä–∏–±–ª–∏–∂–∞–≤–∞–Ω–µ –∫—ä–º –ª–∏–º–∏—Ç–∞
- Data –∑–∞ –ø–æ-–Ω–∞—Ç–∞—Ç—ä—à–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

---

### Solution 5: **Conversation Auto-Reset** (LAST RESORT) üîÑ

–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∏–∑—á–∏—Å—Ç–∏ –∏—Å—Ç–æ—Ä–∏—è—Ç–∞ –∫–æ–≥–∞—Ç–æ –¥–æ—Å—Ç–∏–≥–Ω–µ threshold.

#### Implementation:

```javascript
// –í quendooClaudeIntegration.js
const TOKEN_THRESHOLD = 150000; // 75% –æ—Ç –ª–∏–º–∏—Ç–∞

// Before each request
const estimatedTokens = estimateTokens(history);
if (estimatedTokens > TOKEN_THRESHOLD) {
  console.warn(`[Quendoo] History approaching token limit (${estimatedTokens} tokens), clearing old messages`);

  // Keep only last 2 turns
  const keepMessages = 8; // 2 turns √ó 4 messages
  if (history.length > keepMessages) {
    const removed = history.length - keepMessages;
    history.splice(0, removed);
    console.log(`[Quendoo] Removed ${removed} old messages from history`);
  }
}
```

---

## üéØ –ü–†–ï–ü–û–†–™–ß–ê–ù–ê –°–¢–†–ê–¢–ï–ì–ò–Ø (HYBRID APPROACH)

–ö–æ–º–±–∏–Ω–∞—Ü–∏—è –æ—Ç –≥–æ—Ä–Ω–∏—Ç–µ —Ä–µ—à–µ–Ω–∏—è:

### Phase 1: **Immediate Fixes** (Deploy —Å–µ–≥–∞)
1. ‚úÖ **Reduce excerpt size:** 800 ‚Üí 500 chars (–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–æ –≤ Solution 2A)
2. ‚úÖ **Reduce default results:** 3 ‚Üí 2 documents (–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–æ –≤ Solution 2B)
3. ‚úÖ **Add token monitoring:** Log actual usage (–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–æ –≤ Solution 4)

**–û—á–∞–∫–≤–∞–Ω–æ:** ~40% –Ω–∞–º–∞–ª–µ–Ω–∏–µ –Ω–∞ tool result size

---

### Phase 2: **Smart Truncation** (Deploy —Ç–∞–∑–∏ —Å–µ–¥–º–∏—Ü–∞)
1. ‚úÖ **Implement smartTruncateHistory()** (–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–æ –≤ Solution 1)
2. ‚úÖ **Keep last 3 turns fully, truncate older tool results**
3. ‚úÖ **Test with real conversations**

**–û—á–∞–∫–≤–∞–Ω–æ:** ~70% –Ω–∞–º–∞–ª–µ–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—è –æ—Ç —Å—Ç–∞—Ä–∏ tool results

---

### Phase 3: **Prevention** (Deploy —Å–ª–µ–¥–≤–∞—â–∞ —Å–µ–¥–º–∏—Ü–∞)
1. ‚úÖ **Rate limit tool calls:** Max 3 per turn (–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–æ –≤ Solution 3)
2. ‚úÖ **Auto-reset –ø—Ä–∏ threshold** (–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–Ω–æ –≤ Solution 5)
3. ‚úÖ **Frontend "Clear History" button**

**–û—á–∞–∫–≤–∞–Ω–æ:** –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç—è–≤–∞ token explosions –Ω–∞–ø—ä–ª–Ω–æ

---

## üìà Expected Impact

### Current State (BEFORE):
- History (20 msgs): ~18,000 tokens (with full tool results)
- **Risk of hitting 200K limit:** ‚ö†Ô∏è HIGH (–ø—Ä–∏ 10+ tool calls)

### After Phase 1 (IMMEDIATE):
- Tool results: 590 ‚Üí **~350 tokens** (-40%)
- History (20 msgs): ~11,000 tokens
- **Risk:** ‚ö†Ô∏è MEDIUM

### After Phase 2 (THIS WEEK):
- Old tool results: 590 ‚Üí **~10 tokens** (-98%)
- History (20 msgs): **~6,000 tokens** (only last 3 turns fully)
- **Risk:** ‚úÖ LOW

### After Phase 3 (NEXT WEEK):
- Max 3 tool calls per turn
- Auto-reset –ø—Ä–∏ 150K tokens
- **Risk:** ‚úÖ VERY LOW (elimated token explosions)

---

## üöÄ Implementation Priority

### üî¥ URGENT (Deploy –¥–Ω–µ—Å):
1. Add token usage monitoring (Solution 4)
2. Reduce excerpt size to 500 chars (Solution 2A)

### üü° HIGH (Deploy —Ç–∞–∑–∏ —Å–µ–¥–º–∏—Ü–∞):
1. Implement smart truncation (Solution 1)
2. Reduce default results to 2 (Solution 2B)

### üü¢ MEDIUM (Deploy —Å–ª–µ–¥–≤–∞—â–∞ —Å–µ–¥–º–∏—Ü–∞):
1. Rate limit tool calls (Solution 3)
2. Auto-reset threshold (Solution 5)

---

## üìù Testing Plan

### Test Scenario 1: Document Search (Heavy)
- User: "–ø–æ–∫–∞–∂–∏ –º–∏ —Ä–µ–∑–µ—Ä–≤–∞—Ü–∏—è 442231"
- Expected: 1 tool call, ~350 tokens result
- Repeat 5 times
- Expected total: ~5,000 + (5 √ó 350) = **~6,750 tokens**

### Test Scenario 2: Mixed Operations
- 3√ó document searches
- 2√ó make_call
- 1√ó list_documents
- Expected: ~5,000 + (3√ó350 + 2√ó250 + 1√ó200) = **~6,800 tokens**

### Test Scenario 3: Long Conversation (20+ turns)
- Simulate 20 user messages with various operations
- Smart truncation should keep only last 3 turns fully
- Expected: ~5,000 + (3 turns √ó 400 avg) = **~6,200 tokens**
- Old messages: 17 turns √ó 10 tokens (truncated) = **~170 tokens**
- **Total: ~6,370 tokens** (3.2% –æ—Ç –ª–∏–º–∏—Ç–∞)

---

## ‚úÖ Success Metrics

1. **Token usage < 50K** –∑–∞ –Ω–æ—Ä–º–∞–ª–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Å–∞—Ü–∏—è (10-15 turns)
2. **No token limit errors** –ø—Ä–∏ 20+ turns —Å smart truncation
3. **Response quality maintained** (Claude –∏–º–∞ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç)
4. **User satisfaction** (–Ω–µ –≥—É–±–∏ –≤–∞–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç –∏—Å—Ç–æ—Ä–∏—è—Ç–∞)

---

## üîß Rollback Plan

–ê–∫–æ –∏–º–∞ –ø—Ä–æ–±–ª–µ–º–∏:
1. **Revert excerpt size:** 500 ‚Üí 800 chars
2. **Disable smart truncation:** Keep full history
3. **Fall back to:** History limit = 12 messages (3 turns) –±–µ–∑ truncation

---

## üìû Next Steps

1. **Review this plan** —Å –µ–∫–∏–ø–∞
2. **Approve Phase 1** –∑–∞ deployment –¥–Ω–µ—Å
3. **Deploy & monitor** token usage logs
4. **Analyze real data** —Å–ª–µ–¥ 24 —á–∞—Å–∞
5. **Plan Phase 2** implementation –Ω–∞ –±–∞–∑–∞ —Ä–µ–∞–ª–Ω–∏ –¥–∞–Ω–Ω–∏
